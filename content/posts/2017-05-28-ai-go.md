---
author: "川叶"
date: 2017-05-28
slug: ai go
title: 臭棋带来的快乐，人工智能也可以有吗？
categories: [随笔]
tags: [人工智能,信息技术,科幻]
isCJKLanguage: true
---

本文发表于《[上海观察](https://web.shobserver.com/news/detail?id=54540)》

# 臭棋带来的快乐

马云近日在机器智能高峰论坛上表示：“下围棋本来多有乐趣，结果机器从来不下臭棋，快乐都没了，有啥意思？”

话音刚落，在古力和连笑分别与AlphaGo配对比赛中，古力的阿尔法“队友”要求认输，古力不肯，结果AlphaGo暴走乱落子，看似它有了情绪，引得众人发笑——臭棋果然能带来快乐，马云所言不虚。

<!--more-->

而19岁少年柯洁，代表当今人类围棋手的最高水平。在迎战AlphaGo的前夜，他在微博上写下这样一段话：

> “……__我相信未来是属于人工智能的。可它始终都是冷冰冰的机器，与人类相比，我感觉不到它对围棋的热情和热爱。对它而言...它的热情——也只不过是运转速度过快导致CPU发热罢了。”

毫无疑问，柯洁如今取得的成就，和他对围棋持久的热爱息息相关。对于人类来说，“热情”是我们从事许多活动的自身出发点。这也是现今的人工智能和人类最大的不同——它不但是没有“热情”，连情绪波动都没有。

难怪人们总纠结于一个更深刻、也是老生常谈的话题：人工智能可能具备人的情感吗？进一步说，人工智能是否能获得自我意识呢？

“自我意识”或者“自由意志”，在哲学和生理心理学看来，仍然是晦暗不明、有待检验的存在，在此不表。而“情感”则是一个更加具体而直接的概念，在这个层次上，人工智能可以实现吗？

# 比穷举法更好的方法

AlphaGo的出现，让“人工神经网络”这项技术获得了前所未有的公众关注。

人们很容易联想到，1997年由IBM 开发的“深蓝”击败了人类国际象棋冠军，那件往事，可谓人机对弈的“鼻祖”。

“深蓝”的方法非常直观易懂：电脑可以根据战况沙盘推演之后可能的棋局，给每一种选择计算出评分，从而选择最优的走法。

然而我们知道，围棋的复杂程度是国际象棋的10的120次方倍以上。国际象棋的棋盘较小、规则约束多；围棋棋盘更大、规则约束少。在这种天文数字级的差异面前，“深蓝”的暴力穷举法，即使以当今电脑的计算能力，仍然难以应对。这就使得研究者不得不寻求更好的方法，来解决计算机下围棋的问题。

而AlphaGo采取的“人工神经网络”，则是另一种办法。它受生物神经元的基本结构启发，通过简单神经元的层层输入输出，实现复杂的决策过程。简言之，传统的编程方法，是“为了解决一个问题，写出相应的程序代码”；而“人工神经网络”在编写底层的代码之后，还具有很高的通用性，可以解决各种不同类型的问题。这就好比，生物的每一个神经元都很类似，但是大脑还是能有不同的功能分工一样。

# 只会计算，不会思考？

那人工神经网络是怎样实现不同的功能呢？

它能识别图像、识别语音、自动驾驶……也能下围棋，这并不是人去写了“如何识别图像”“如何下围棋”这类的程序代码，而是用实例“训练”出来的。这里的“训练”，并不是比喻，而是和人训练猫猫狗狗，和人做练习题一样，其本质是相通的。

柯洁苦练了十几年，而AlphaGo的训练量显然超过了柯洁。据报道，与柯洁对弈的版本，是由电脑在掌握了基本的围棋规则后，不断地自己和自己下棋，总结经验教训，从而习得的棋力。相当于在短时间内，电脑已经重复了人类两千年的对弈史，并且开辟了自己的套路。电脑并不需要去穷举围棋的每一种可能性，而是像人那样，在对弈中总结经验，从而对赢面有“直观”的感知，然后根据自己的判断下棋即可。

以往针对人工智能，常常能听到这样的论调：“电脑只会计算，并不会思考。”人工神经网络的应用则告诉我们，“思考”这种行为，建立在数量庞大的神经元的简单计算过程之上。单个神经元很简单，众多神经元协作则变得复杂，而且，可能复杂到我们难以探究一些“思考”的细节。

虽然今天尚且没有人能肯定，计算机是否已经掌握了“思考”的方法，但毫无疑问，有了人工神经网络的存在，“深度学习”的应用能力，将不是传统的“计算”可以比拟的。

# 可以“训练”的情感

动物学家已经搞清楚了，灵长类动物是个情感丰富的物种。而人类的情感尤其丰富，这也是人类可以自诩万物之灵的资本。人类学和社会心理学同时告诉我们，我们的情感好恶，有很大程度上来源于后天的社会构建。

如果人类的小孩并没有在人类社会中成长，那他将不会拥有一个普通人的情感，比如“狼孩”的传说。心理学家的实验证明，幼年时的心理反馈可以影响成年乃至一生。在不同的社会文化中，人们对某些事情的好恶和情感差别，可能相当大。而在日常生活中我们也能感受到，一个人的教养，和家庭教育、学校教育息息相关。以上这些都说明，人类的“情感”是可以习得的，是可以训练出来的。

大脑的不同分区，承担着处理不同情感活动的功能。而这些大脑分区，都有着基本结构相同的神经元。神经元的连接方式不同，导致了功能的不同，但从单个神经元的基本功能上来说，负责处理理性思考的、负责处理艺术创作的、负责处理运动协调的神经元，和负责处理情感的单个神经元，没有什么本质上的不同。

这大概就是人工智能是否能习得情感的关键——**如果“人工神经网络”可以被训练成图像识别小能手、围棋传说终结者，那么在理论上，它也有潜力被训练成“知心姐姐”。**

# 不会“说话”的情感

那为什么直到今天，我们并没有看到充满感情的机器人出现呢？为什么与柯洁对战的是代表AlphaGo的二传手、研究员黄博士，而不是一个自带表情包的机器人呢？

生产充满感情的机器人，需要解决另一个关键问题——自然语言处理。

教会机器人下棋已经实现，但教会机器人说人话更难。人类的语言复杂多变，规律性有限，约定俗成多。即使是人类的小孩，学习语言尚且需要经历十年以上的时间才能熟练掌握，更别说人工神经网络了。

缺少了熟练表达的语言作为载体，情感也就难以表达。这就好比一个木讷的少年，它的内心再汹涌，你也难以窥探究竟。没有这个前提，人工智能的情感也就无法有效地训练。

但其实生活中，你已经可以体验到最基础的人工智能“情感”了。苹果公司的 Siri 有时候会以比较戏谑的方式回应你的一些指令——虽然我们知道这是还很拙劣的“强行加戏”，但仍然不妨碍我们会心一笑，甚至无聊时，我们还可以以“调戏”Siri 为乐。

比如：

> 用户：你能不能讲个故事给我听？

> Siri：好的，我讲的故事你可能听过了：从前有座山，山里有座庙，庙里有个老和尚，有一天老和尚对小和尚说我给你讲个故事吧：从前有座山，哈。哈。

从产品设计的角度来说，这有助于用户在 Siri 犯傻时给予原谅。而在这背后，则是一个较为沉重的心理学问题——人是易受情感影响的。设计师正是利用了这种心理，让笨笨的 Siri 具备了一定的“魅力”。

Siri 当然不能作为人工智能拥有情感的代表。目前为止，应该说尚无真正实现了有效情感互动的人工智能，尽管也出现了一些诸如“情感陪护机器人”这类的创业概念。但 Siri 的情感模仿，证明了人类对情感的要求其实不是很高，并不一定要一个表达能力好、智力高的人才能形成情感互动，**就好比人和作为宠物的狗、猫、鸟甚至爬行类和鱼类，都可能形成强有力的情感纽带一样**。

# 选择权还在我们手中

让机器拥有情感，一方面是“做不做得到”的问题，另一方面是“应不应该做”的问题。

从各种原理来讲，以现有的技术手段，实现具备情感互动能力的机器人并非完全不可能，只是暂时缺少一些契机。但是，如果这一天真的来临，我们又会面临一些根本问题。

无论你是否赞成“一个东西看起来和人没有任何区别，那这个东西就是人”的判断标准，都无法否认一个事实：**如果一个机器具备人的情感，那么总会有人无法忽视它的情感。**毕竟，人是十分容易受情感控制的生物。

那个时候，机器是否应该得到礼貌的对待、是否应该具有权利等，都可能会被提上社会议程。

AlphaGo的研究人员表示，和柯洁的比赛结束后，他们将考虑AlphaGo的去留。可以想象一下，如果AlphaGo被训练成能够表达情感，那么它可以在最后一局向直播的观众们表示：

> “这些天来，我觉得和柯洁已经成为了很好的朋友，我也舍不得离开大家，希望今后能继续和各位老师比赛下棋。”

那么，还有人舍得关闭它么？

如果人工智能真的掌握了人类情感的奥秘，也就学会了通过情感影响人类的行为。如果它继续学习心理学、传播学、社会学……呢？

在电影 Ex Machina（机械降神）中，外形姣好的模仿人类女性的机器人，利用程序员的感情，逃出生天。这样的情节是否会变成现实？

至少到目前为止，选择权还在人类手中。对于机器来说，赋予它们初级智能的人类工程师，好比盗火的普罗米修斯，当星星之火开始燎原的时候，可能这火种，也很难消灭了。
